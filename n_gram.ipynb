{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>post_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>작년 겨울에는 인제 자작나무숲을 다녀왔었어요</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>그때는 코로나가 없는 시절이라 그런지 사람이 굉장히 많고 가는길이 넘 힘들어서 생각...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>맛있는 저녁을 먹고 다음날 일출을 보겠노라 호텔 앞 바다로 나갔는데 구름 때문에 해...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>이때까지도 좋았어요 짐을 챙겨 인제로 넘어가기 전 갑자기 떠오른 태양 하늘이 또 얼...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>룰루랄라 차 안에서 노래도 부르고 수다 떨고 도착 아니 전국 사람 인제 자작나무 숲...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488767</th>\n",
       "      <td>카카오톡 환급신청 방법은 지방세 환급통지서를 받은 군민에 한해 가능합니다</td>\n",
       "      <td>24915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488768</th>\n",
       "      <td>카카오톡 채널 인제군지방세환급 검색 후 1 1 채팅하기로 성명 생년월일 은행명 계좌...</td>\n",
       "      <td>24915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488769</th>\n",
       "      <td>인제군지방세환급 바로 가기 http pf kakao com UPtjb 인제군지방세환...</td>\n",
       "      <td>24915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488770</th>\n",
       "      <td>1 1 대화하기로 잠자고 있는 환급금을 신청하세요</td>\n",
       "      <td>24915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488771</th>\n",
       "      <td>pf kakao com 하늘내린인제 강원도인제 인제군 인제 지방세 지방세환급 지방세환급금</td>\n",
       "      <td>24915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>488772 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  post_index\n",
       "0                                작년 겨울에는 인제 자작나무숲을 다녀왔었어요           0\n",
       "1       그때는 코로나가 없는 시절이라 그런지 사람이 굉장히 많고 가는길이 넘 힘들어서 생각...           0\n",
       "2       맛있는 저녁을 먹고 다음날 일출을 보겠노라 호텔 앞 바다로 나갔는데 구름 때문에 해...           0\n",
       "3       이때까지도 좋았어요 짐을 챙겨 인제로 넘어가기 전 갑자기 떠오른 태양 하늘이 또 얼...           0\n",
       "4       룰루랄라 차 안에서 노래도 부르고 수다 떨고 도착 아니 전국 사람 인제 자작나무 숲...           0\n",
       "...                                                   ...         ...\n",
       "488767           카카오톡 환급신청 방법은 지방세 환급통지서를 받은 군민에 한해 가능합니다       24915\n",
       "488768  카카오톡 채널 인제군지방세환급 검색 후 1 1 채팅하기로 성명 생년월일 은행명 계좌...       24915\n",
       "488769  인제군지방세환급 바로 가기 http pf kakao com UPtjb 인제군지방세환...       24915\n",
       "488770                        1 1 대화하기로 잠자고 있는 환급금을 신청하세요       24915\n",
       "488771  pf kakao com 하늘내린인제 강원도인제 인제군 인제 지방세 지방세환급 지방세환급금       24915\n",
       "\n",
       "[488772 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('인제2021문장분리.csv',encoding ='utf-8', sep = '\\t')\n",
    "# df = df[['text']].copy() #text만 남기면서 시리즈가 되지않고 계속 데이터프레임 형태\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[작년 겨울에는 인제 자작나무숲을 다녀왔었어요, 그때는 코로나가 없는 시절이라 그런...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[새해맞이를 산에서 하고 싶었다, 같이 산에 다니는 형님과 둘이서 마장터를 가자고 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[벌써 3개월이 훌쩍 지났네요, 코로나의 역습에 너도 나도 지쳐갈 때 쯤 원대리 자...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[첫 일정이었던 인제 러빙네이처에서 캠핑을 마치고 바로 양양으로 출발했다, 지난 추...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[안녕하세요 카페하추리 입니다, 인제지역 새해특별방역대책 및 사회적거리두기 2단계가...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24720</th>\n",
       "      <td>24911</td>\n",
       "      <td>[강원도 인제 멋진 VIEW를 갖춘 카페 체험상품 3만원 내 이용권 모집인원 20팀...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24721</th>\n",
       "      <td>24912</td>\n",
       "      <td>[gabrielalenius 출처 Unsplash thebeardbe 출처 Unsp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24722</th>\n",
       "      <td>24913</td>\n",
       "      <td>[코로나19 확산을 방지하기 위한 도내 각종 행사 취소 안내 안녕하세요 강원도청입니...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24723</th>\n",
       "      <td>24914</td>\n",
       "      <td>[워낙 딸기를 좋아하는 아이가 내년엔 밭에 딸기를 심고 심다는 말을 했을 때 그러마...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24724</th>\n",
       "      <td>24915</td>\n",
       "      <td>[지방세 환급금 카카오톡으로 신청하세요, 인제군은 2022년 1월부터 지방세 환급신...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24725 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       post_index                                               text\n",
       "0               0  [작년 겨울에는 인제 자작나무숲을 다녀왔었어요, 그때는 코로나가 없는 시절이라 그런...\n",
       "1               1  [새해맞이를 산에서 하고 싶었다, 같이 산에 다니는 형님과 둘이서 마장터를 가자고 ...\n",
       "2               2  [벌써 3개월이 훌쩍 지났네요, 코로나의 역습에 너도 나도 지쳐갈 때 쯤 원대리 자...\n",
       "3               3  [첫 일정이었던 인제 러빙네이처에서 캠핑을 마치고 바로 양양으로 출발했다, 지난 추...\n",
       "4               4  [안녕하세요 카페하추리 입니다, 인제지역 새해특별방역대책 및 사회적거리두기 2단계가...\n",
       "...           ...                                                ...\n",
       "24720       24911  [강원도 인제 멋진 VIEW를 갖춘 카페 체험상품 3만원 내 이용권 모집인원 20팀...\n",
       "24721       24912  [gabrielalenius 출처 Unsplash thebeardbe 출처 Unsp...\n",
       "24722       24913  [코로나19 확산을 방지하기 위한 도내 각종 행사 취소 안내 안녕하세요 강원도청입니...\n",
       "24723       24914  [워낙 딸기를 좋아하는 아이가 내년엔 밭에 딸기를 심고 심다는 말을 했을 때 그러마...\n",
       "24724       24915  [지방세 환급금 카카오톡으로 신청하세요, 인제군은 2022년 1월부터 지방세 환급신...\n",
       "\n",
       "[24725 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.groupby('post_index')['text'].apply(list).reset_index()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['post_index', 'text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords= [\n",
    "    \"가\", \"가까스로\", \"가령\", \"각\", \"각각\", \"각자\", \"각종\", \"갖고말하자면\", \"같다\", \"같이\", \"개의치않고\",\n",
    "    \"거니와\", \"거바\", \"거의\", \"것\", \"것과 같이\", \"것들\", \"게다가\", \"게우다\", \"겨우\", \"견지에서\", \"결과에 이르다\",\n",
    "    \"결국\", \"결론을 낼 수 있다\", \"겸사겸사\", \"고려하면\", \"고로\", \"곧\", \"공동으로\", \"과\", \"과연\", \"관계가 있다\",\n",
    "    \"관계없이\", \"관련이 있다\", \"관하여\", \"관한\", \"관해서는\", \"구\", \"구체적으로\", \"구토하다\", \"그\", \"그들\", \"그때\",\n",
    "    \"그래\", \"그래도\", \"그래서\", \"그러나\", \"그러니\", \"그러니까\", \"그러면\", \"그러므로\", \"그러한즉\", \"그런 까닭에\",\n",
    "    \"그런데\", \"그런즉\", \"그럼\", \"그럼에도 불구하고\", \"그렇게 함으로써\", \"그렇지\", \"그렇지 않다면\", \"그렇지 않으면\",\n",
    "    \"그렇지만\", \"그렇지않으면\", \"그리고\", \"그리하여\", \"그만이다\", \"그에 따르는\", \"그위에\", \"그저\", \"그중에서\",\n",
    "    \"그치지 않다\", \"근거로\", \"근거하여\", \"기대여\", \"기점으로\", \"기준으로\", \"기타\", \"까닭으로\", \"까악\", \"까지\",\n",
    "    \"까지 미치다\", \"까지도\", \"꽈당\", \"끙끙\", \"끼익\", \"나\", \"나머지는\", \"남들\", \"남짓\", \"너\", \"너희\", \"너희들\", \"네\",\n",
    "    \"넷\", \"년\", \"논하지 않다\", \"놀라다\", \"누가 알겠는가\", \"누구\", \"다른\", \"다른 방면으로\", \"다만\", \"다섯\", \"다소\",\n",
    "    \"다수\", \"다시 말하자면\", \"다시말하면\", \"다음\", \"다음에\", \"다음으로\", \"단지\", \"답다\", \"당신\", \"당장\", \"대로 하다\",\n",
    "    \"대하면\", \"대하여\", \"대해 말하자면\", \"대해서\", \"댕그\", \"더구나\", \"더군다나\", \"더라도\", \"더불어\", \"더욱더\",\n",
    "    \"더욱이는\", \"도달하다\", \"도착하다\", \"동시에\", \"동안\", \"된바에야\", \"된이상\", \"두번째로\", \"둘\", \"둥둥\", \"뒤따라\",\n",
    "    \"뒤이어\", \"든간에\", \"들\", \"등\", \"등등\", \"딩동\", \"따라\", \"따라서\", \"따위\", \"따지지 않다\", \"딱\", \"때\", \"때가 되어\",\n",
    "    \"때문에\", \"또\", \"또한\", \"뚝뚝\", \"라 해도\", \"령\", \"로\", \"로 인하여\", \"로부터\", \"로써\", \"륙\", \"를\", \"마음대로\",\n",
    "    \"마저\", \"마저도\", \"마치\", \"막론하고\", \"만 못하다\", \"만약\", \"만약에\", \"만은 아니다\", \"만이 아니다\", \"만일\", \"만큼\",\n",
    "    \"말하자면\", \"말할것도 없고\", \"매\", \"매번\", \"메쓰겁다\", \"몇\", \"모\", \"모두\", \"무렵\", \"무릎쓰고\", \"무슨\", \"무엇\",\n",
    "    \"무엇때문에\", \"물론\", \"및\", \"바꾸어말하면\", \"바꾸어말하자면\", \"바꾸어서 말하면\", \"바꾸어서 한다면\", \"바꿔 말하면\",\n",
    "    \"바로\", \"바와같이\", \"밖에 안된다\", \"반대로\", \"반대로 말하자면\", \"반드시\", \"버금\", \"보는데서\", \"보다더\", \"보드득\",\n",
    "    \"본대로\", \"봐\", \"봐라\", \"부류의 사람들\", \"부터\", \"불구하고\", \"불문하고\", \"붕붕\", \"비걱거리다\", \"비교적\", \"비길수 없다\",\n",
    "    \"비로소\", \"비록\", \"비슷하다\", \"비추어 보아\", \"비하면\", \"뿐만 아니라\", \"뿐만아니라\", \"뿐이다\", \"삐걱\", \"삐걱거리다\",\n",
    "    \"사\", \"삼\", \"상대적으로 말하자면\", \"생각한대로\", \"설령\", \"설마\", \"설사\", \"셋\", \"소생\", \"소인\", \"솨\", \"쉿\", \"습니까\",\n",
    "    \"습니다\", \"시각\", \"시간\", \"시작하여\", \"시초에\", \"시키다\", \"실로\", \"심지어\", \"아\", \"아니\", \"아니나다를가\", \"아니라면\",\n",
    "    \"아니면\", \"아니었다면\", \"아래윗\", \"아무거나\", \"아무도\", \"아야\", \"아울러\", \"아이\", \"아이고\", \"아이구\", \"아이야\",\n",
    "    \"아이쿠\", \"아하\", \"아홉\", \"안 그러면\", \"않기 위하여\", \"않기 위해서\", \"알 수 있다\", \"알았어\", \"앗\", \"앞에서\",\n",
    "    \"앞의것\", \"야\", \"약간\", \"양자\", \"어\", \"어기여차\", \"어느\", \"어느 년도\", \"어느것\", \"어느곳\", \"어느때\", \"어느쪽\",\n",
    "    \"어느해\", \"어디\", \"어때\", \"어떠한\", \"어떤\", \"어떤것\", \"어떤것들\", \"어떻게\", \"어떻해\", \"어이\", \"어째서\", \"어쨋든\",\n",
    "    \"어쩔수 없다\", \"어찌\", \"어찌됏든\", \"어찌됏어\", \"어찌하든지\", \"어찌하여\", \"언제\", \"언젠가\", \"얼마\", \"얼마 안 되는 것\",\n",
    "    \"얼마간\", \"얼마나\", \"얼마든지\", \"얼마만큼\", \"얼마큼\", \"엉엉\", \"에\", \"에 가서\", \"에 달려 있다\", \"에 대해\", \"에 있다\",\n",
    "    \"에 한하다\", \"에게\", \"에서\", \"여\", \"여기\", \"여덟\", \"여러분\", \"여보시오\", \"여부\", \"여섯\", \"여전히\", \"여차\", \"연관되다\",\n",
    "    \"연이서\", \"영\", \"영차\", \"옆사람\", \"예\", \"예를 들면\", \"예를 들자면\", \"예컨대\", \"예하면\", \"오\", \"오로지\", \"오르다\",\n",
    "    \"오자마자\", \"오직\", \"오호\", \"오히려\", \"와\", \"와 같은 사람들\", \"와르르\", \"와아\", \"왜\", \"왜냐하면\", \"외에도\", \"요만큼\",\n",
    "    \"요만한 것\", \"요만한걸\", \"요컨대\", \"우르르\", \"우리\", \"우리들\", \"우선\", \"우에 종합한것과같이\", \"운운\", \"월\", \"위에서 서술한바와같이\",\n",
    "    \"위하여\", \"위해서\", \"윙윙\", \"육\", \"으로\", \"으로 인하여\", \"으로서\", \"으로써\", \"을\", \"응\", \"응당\", \"의\", \"의거하여\",\n",
    "    \"의지하여\", \"의해\", \"의해되다\", \"의해서\", \"이\", \"이 되다\", \"이 때문에\", \"이 밖에\", \"이 외에\", \"이 정도의\", \"이것\", \"이곳\",\n",
    "    \"이때\", \"이라면\", \"이래\", \"이러이러하다\", \"이러한\", \"이런\", \"이럴정도로\", \"이렇게 많은 것\", \"이렇게되면\", \"이렇게말하자면\",\n",
    "    \"이렇구나\", \"이로 인하여\", \"이르기까지\", \"이리하여\", \"이만큼\", \"이번\", \"이봐\", \"이상\", \"이어서\", \"이었다\", \"이와 같다\",\n",
    "    \"이와 같은\", \"이와 반대로\", \"이와같다면\", \"이외에도\", \"이용하여\", \"이유만으로\", \"이젠\", \"이지만\", \"이쪽\", \"이천구\",\n",
    "    \"이천육\", \"이천칠\", \"이천팔\", \"인 듯하다\", \"인젠\", \"일\", \"일것이다\", \"일곱\", \"일단\", \"일때\", \"일반적으로\", \"일지라도\",\n",
    "    \"임에 틀림없다\", \"입각하여\", \"입장에서\", \"잇따라\", \"있다\", \"자\", \"자기\", \"자기집\", \"자마자\", \"자신\", \"잠깐\", \"잠시\",\n",
    "    \"저\", \"저것\", \"저것만큼\", \"저기\", \"저쪽\", \"저희\", \"전부\", \"전자\", \"전후\", \"점에서 보아\", \"정도에 이르다\", \"제\", \"제각기\",\n",
    "    \"제외하고\", \"조금\", \"조차\", \"조차도\", \"졸졸\", \"좀\", \"좋아\", \"좍좍\", \"주룩주룩\", \"주저하지 않고\", \"줄은 몰랏다\", \"줄은모른다\",\n",
    "    \"중에서\", \"중의하나\", \"즈음하여\", \"즉\", \"즉시\", \"지든지\", \"지만\", \"지말고\", \"진짜로\", \"쪽으로\", \"차라리\", \"참\", \"참나\",\n",
    "    \"첫번째로\", \"쳇\", \"총적으로\", \"총적으로 말하면\", \"총적으로 보면\", \"칠\", \"콸콸\", \"쾅쾅\", \"쿵\", \"타다\", \"타인\", \"탕탕\",\n",
    "    \"토하다\", \"통하여\", \"툭\", \"퉤\", \"틈타\", \"팍\", \"팔\", \"퍽\", \"펄렁\", \"하\", \"하게될것이다\", \"하게하다\", \"하겠는가\", \"하고 있다\",\n",
    "    \"하고있었다\", \"하곤하였다\", \"하구나\", \"하기 때문에\", \"하기 위하여\", \"하기는한데\", \"하기만 하면\", \"하기보다는\", \"하기에\",\n",
    "    \"하나\", \"하느니\", \"하는 김에\", \"하는 편이 낫다\", \"하는것도\", \"하는것만 못하다\", \"하는것이 낫다\", \"하는바\", \"하더라도\",\n",
    "    \"하도다\", \"하도록시키다\", \"하도록하다\", \"하든지\", \"하려고하다\", \"하마터면\", \"하면 할수록\", \"하면된다\", \"하면서\",\n",
    "    \"하물며\", \"하여금\", \"하여야\", \"하자마자\", \"하지 않는다면\", \"하지 않도록\", \"하지마\", \"하지마라\", \"하지만\", \"하하\",\n",
    "    \"한 까닭에\", \"한 이유는\", \"한 후\", \"한다면\", \"한다면 몰라도\", \"한데\", \"한마디\", \"한적이있다\", \"한켠으로는\", \"한항목\",\n",
    "    \"할 따름이다\", \"할 생각이다\", \"할 줄 안다\", \"할 지경이다\", \"할 힘이 있다\", \"할때\", \"할만하다\", \"할망정\", \"할뿐\",\n",
    "    \"할수있다\", \"할수있어\", \"할줄알다\", \"할지라도\", \"할지언정\", \"함께\", \"해도된다\", \"해도좋다\", \"해봐요\", \"해서는 안된다\",\n",
    "    \"해야한다\", \"해요\", \"했어요\", \"향하다\", \"향하여\", \"향해서\", \"허\", \"허걱\", \"허허\", \"헉\", \"헉헉\", \"헐떡헐떡\", \"형식으로 쓰여\",\n",
    "    \"혹시\", \"혹은\", \"혼자\", \"훨씬\", \"휘익\", \"휴\", \"흐흐\", \"흥\", \"힘입어\", \"하다\",\"이다\",\"을\",'를','이','가','이미','거죠','있는','그래서','아무튼',\n",
    "    '라고','있으니','있으니까','11','naver','있어서','나는','50m','합니다','com','한다','그런','.','있어','있는데','있었다','이거','입니다','했다',\n",
    "    '스티커입니다','존재하지','00','15','이건','있어요','것이','하는','저도','이렇게','하고','있습니다','내가','제가','이게','그런지','그냥','됩니다',\n",
    "    'corp','10','000원','그렇게','있었어요','하면','해서','blog','해서','안녕하세요','나도','있을','따로',\n",
    "    '뭔가','되어','같은','역시','있었습니다','거예요','같습니다','항상','없을','없다','없어요','저는','구글','같아요','않는',\n",
    "    '너무','있고','싶은','대한','다들','것을','완전','전에','수도','갑자기','존재','스티커','재생',\n",
    "    '나의','않은','것이다','해야','진짜','동영상','리빙','네이쳐','때문','때문에','이다','스티커','존재','존재하지','존재하지않는','존재하지 않는',\n",
    "    '이미지','재생','접기','접다','중간','링크','나도','나는','내가','나노','칼슘'\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-16 10:58:35,139 [INFO] 로그 파일 저장 위치: C:\\Users\\user\\Desktop\\아나콘다_data_code\\workspace\\process.log\n",
      "2025-05-16 10:58:35,140 [INFO] 데이터 파일 읽는 중\n",
      "2025-05-16 10:58:35,874 [INFO] 데이터 로딩 완료. shape: (488772, 1)\n",
      "2025-05-16 10:58:35,876 [INFO] 한 글자 단어 제거 중...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 6 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "\n",
      "WARNING: You are on Windows. If you detect any issue with pandarallel, be sure you checked out the Troubleshooting page:\n",
      "https://nalepae.github.io/pandarallel/troubleshooting/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fb3a6c054fb4d7ba2ff800ec99d9565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=81462), Label(value='0 / 81462')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-16 10:58:38,634 [INFO] 불용어 제거 중...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6ff797d13504636ab8ac062ed4e981b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=81462), Label(value='0 / 81462')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-16 10:58:40,910 [INFO] 형태소 분석 중...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "492af8b0c8a54d469deedd8745434222",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=81462), Label(value='0 / 81462')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-16 11:01:28,499 [INFO] 복합명사 합치기 중...\n",
      "2025-05-16 11:01:30,083 [INFO] 다시 불용어 제거 중...\n",
      "2025-05-16 11:01:30,721 [INFO] 바이그램 생성 중...\n",
      "2025-05-16 11:01:31,757 [INFO] 바이그램 빈도 집계 중...\n",
      "2025-05-16 11:01:32,802 [INFO] 유니그램 빈도 집계 중...\n",
      "2025-05-16 11:01:33,164 [INFO] PMI 계산 중...\n",
      "2025-05-16 11:01:34,972 [INFO] 작업 끄읏 ~~~ 결과가 C:\\Users\\user\\Desktop\\아나콘다_data_code\\workspace에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import logging\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from pandarallel import pandarallel\n",
    "from tqdm import tqdm\n",
    "\n",
    "# tqdm + pandas 연동\n",
    "tqdm.pandas()\n",
    "\n",
    "# 불용어 리스트 정의 (예시)\n",
    "\n",
    "\n",
    "# 병렬 함수 생성기\n",
    "def get_remove_stop_words_fn(stopwords):\n",
    "    def remove_stop_words(text):\n",
    "        words = text.split()\n",
    "        return ' '.join([word for word in words if word not in stopwords])\n",
    "    return remove_stop_words\n",
    "\n",
    "def get_tokens_sep_fn(stopwords):\n",
    "    def tokens_sep(text):\n",
    "        from konlpy.tag import Okt\n",
    "        okt = Okt()\n",
    "        morphs = okt.pos(text, stem=True)\n",
    "        return [word for word, pos in morphs if pos == 'Noun' and word not in stopwords]\n",
    "    return tokens_sep\n",
    "\n",
    "# 병렬 함수\n",
    "def remove_one_char_words(text):\n",
    "    import re\n",
    "    text = re.sub(r'\\b[가-힣]\\b', '', text)\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "# 로깅 설정\n",
    "def setup_logging(output_dir):\n",
    "    log_path = os.path.join(output_dir, \"process.log\")\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_path, encoding=\"utf-8\"),\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "    logging.info(f\"로그 파일 저장 위치: {log_path}\")\n",
    "\n",
    "# 복합명사 정의\n",
    "COMPOUNDS = [\"브레이크 타임\"]\n",
    "PATTERNS = [(phrase.split(), \"\".join(phrase.split())) for phrase in COMPOUNDS]\n",
    "\n",
    "# 일반 처리 함수들\n",
    "def merge_compound(tokens):\n",
    "    i, merged = 0, []\n",
    "    while i < len(tokens):\n",
    "        matched = False\n",
    "        for parts, joined in PATTERNS:\n",
    "            n = len(parts)\n",
    "            if tokens[i:i+n] == parts:\n",
    "                merged.append(joined)\n",
    "                i += n\n",
    "                matched = True\n",
    "                break\n",
    "        if not matched:\n",
    "            merged.append(tokens[i])\n",
    "            i += 1\n",
    "    return merged\n",
    "\n",
    "def remove_noise(tokens, stopwords):\n",
    "    return [t for t in tokens if len(t) > 1 and t not in stopwords]\n",
    "\n",
    "def make_bigrams(tokens):\n",
    "    return list(zip(tokens, tokens[1:]))\n",
    "\n",
    "def compute_pmi(w1, w2, cnt, unigram_counts, total_tokens, total_bigrams):\n",
    "    p_w1 = unigram_counts[w1] / total_tokens\n",
    "    p_w2 = unigram_counts[w2] / total_tokens\n",
    "    p_w1w2 = cnt / total_bigrams\n",
    "    return math.log2(p_w1w2 / (p_w1 * p_w2)) if p_w1w2 > 0 else 0.0\n",
    "\n",
    "# 메인 프로세스\n",
    "def main(input_path, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    setup_logging(output_dir)\n",
    "\n",
    "    try:\n",
    "        logging.info(\"데이터 파일 읽는 중\")\n",
    "        df = pd.read_csv(input_path, encoding='utf-8', sep='\\t')\n",
    "        df = df[['text']].copy()\n",
    "        logging.info(f\"데이터 로딩 완료. shape: {df.shape}\")\n",
    "\n",
    "        stopwords = set(stopwords_ko)\n",
    "        pandarallel.initialize(progress_bar=True)\n",
    "\n",
    "        remove_stop_words_fn = get_remove_stop_words_fn(stopwords)\n",
    "        tokens_sep_fn = get_tokens_sep_fn(stopwords)\n",
    "\n",
    "        logging.info(\"한 글자 단어 제거 중...\")\n",
    "        df['remove_one_char_words'] = df['text'].parallel_apply(remove_one_char_words)\n",
    "\n",
    "        logging.info(\"불용어 제거 중...\")\n",
    "        df['remove_stopword'] = df['remove_one_char_words'].parallel_apply(remove_stop_words_fn)\n",
    "\n",
    "        logging.info(\"형태소 분석 중...\")\n",
    "        df['noun_tokens'] = df['remove_stopword'].parallel_apply(tokens_sep_fn)\n",
    "\n",
    "        logging.info(\"복합명사 합치기 중...\")\n",
    "        df['noun_tokens_merged'] = df['noun_tokens'].apply(merge_compound)\n",
    "\n",
    "        logging.info(\"다시 불용어 제거 중...\")\n",
    "        df['noun_tokens_merged_clean'] = df['noun_tokens_merged'].apply(lambda x: remove_noise(x, stopwords))\n",
    "\n",
    "        logging.info(\"바이그램 생성 중...\")\n",
    "        df['bigrams'] = df['noun_tokens_merged_clean'].apply(make_bigrams)\n",
    "\n",
    "        logging.info(\"바이그램 빈도 집계 중...\")\n",
    "        all_bigrams = [bg for bg_list in df[\"bigrams\"] for bg in bg_list]\n",
    "        bigram_counts = Counter(all_bigrams)\n",
    "        top200 = bigram_counts.most_common(200)\n",
    "\n",
    "        result_df = pd.DataFrame(top200, columns=[\"bigram\", \"count\"])\n",
    "        result_df[[\"word1\", \"word2\"]] = pd.DataFrame(result_df[\"bigram\"].tolist(), index=result_df.index)\n",
    "        result_df = result_df[[\"word1\", \"word2\", \"count\"]]\n",
    "\n",
    "        logging.info(\"유니그램 빈도 집계 중...\")\n",
    "        all_tokens = [token for tokens in df['noun_tokens_merged_clean'] for token in tokens]\n",
    "        unigram_counts = Counter(all_tokens)\n",
    "        total_tokens = sum(unigram_counts.values())\n",
    "        total_bigrams = sum(bigram_counts.values())\n",
    "\n",
    "        logging.info(\"PMI 계산 중...\")\n",
    "        result_df['PMI'] = result_df.apply(\n",
    "            lambda row: compute_pmi(row['word1'], row['word2'], row['count'],\n",
    "                                    unigram_counts, total_tokens, total_bigrams),\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        result_df.to_csv(os.path.join(output_dir, \"bigram_top200.csv\"), encoding='utf-8', index=False)\n",
    "        df[['bigrams']].to_csv(os.path.join(output_dir, \"bigram_rawpair.csv\"), encoding='utf-8', index=False)\n",
    "\n",
    "        logging.info(f\"작업 끄읏 ~~~ 결과가 {output_dir}에 저장되었습니다.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"에러 발생: {e}\", exc_info=True)\n",
    "\n",
    "# 실행\n",
    "if __name__ == \"__main__\":\n",
    "    input_path = r\"C:\\Users\\user\\Desktop\\아나콘다_data_code\\workspace\\인제2021문장분리.csv\"\n",
    "    output_dir = r\"C:\\Users\\user\\Desktop\\아나콘다_data_code\\workspace\"\n",
    "    main(input_path, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>post_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>이렇게 따끈따끈한 근황 업로드는 처음이다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>기억이 증발하기 전에 기록 코로나 확진자 다섯자리 시대라 이런 글 나름 조심스럽지만...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>물론 기태시 하드캐리 2022 01 22 토 인제 자작나무 숲 대관령 전날 밤 강릉...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>아니 암만 그래도 왤케 빨리 시작하냐고 입장시간이 애초에 오후 2시거던</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>용 심지어 주차장에서부터 1시간 반 걸림</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490594</th>\n",
       "      <td>모든장소가 맘에 쏙들어 저녁에도 도랏 분위기 도랏 밤에 별도 많이보임</td>\n",
       "      <td>25387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490595</th>\n",
       "      <td>우리가 해먹은 음식들 펜션 안에 있는 그릇들도 다 너무 이뻐서 거기에맞게 플레이팅까...</td>\n",
       "      <td>25387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490596</th>\n",
       "      <td>반려견키우시는분들께 강추 여자들끼리와도 너무 좋을듯한 갬성펜션 너무아쉬웠던 1박 2...</td>\n",
       "      <td>25387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490597</th>\n",
       "      <td>제부여객 2번 구간 1 2번 경진여객차고지 기점 조암시장 장안여자중학교 사곡사거리 ...</td>\n",
       "      <td>25388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490598</th>\n",
       "      <td>노선변경 1 2022 10 1일부로 조암터미널 만료로 인해 조암터미널 조암시장으로 ...</td>\n",
       "      <td>25388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>490599 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  post_index\n",
       "0                                  이렇게 따끈따끈한 근황 업로드는 처음이다           0\n",
       "1       기억이 증발하기 전에 기록 코로나 확진자 다섯자리 시대라 이런 글 나름 조심스럽지만...           0\n",
       "2       물론 기태시 하드캐리 2022 01 22 토 인제 자작나무 숲 대관령 전날 밤 강릉...           0\n",
       "3                 아니 암만 그래도 왤케 빨리 시작하냐고 입장시간이 애초에 오후 2시거던           0\n",
       "4                                  용 심지어 주차장에서부터 1시간 반 걸림           0\n",
       "...                                                   ...         ...\n",
       "490594             모든장소가 맘에 쏙들어 저녁에도 도랏 분위기 도랏 밤에 별도 많이보임       25387\n",
       "490595  우리가 해먹은 음식들 펜션 안에 있는 그릇들도 다 너무 이뻐서 거기에맞게 플레이팅까...       25387\n",
       "490596  반려견키우시는분들께 강추 여자들끼리와도 너무 좋을듯한 갬성펜션 너무아쉬웠던 1박 2...       25387\n",
       "490597  제부여객 2번 구간 1 2번 경진여객차고지 기점 조암시장 장안여자중학교 사곡사거리 ...       25388\n",
       "490598  노선변경 1 2022 10 1일부로 조암터미널 만료로 인해 조암터미널 조암시장으로 ...       25388\n",
       "\n",
       "[490599 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('인제2022문장분리.csv',encoding ='utf-8', sep = '\\t')\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[이렇게 따끈따끈한 근황 업로드는 처음이다, 기억이 증발하기 전에 기록 코로나 확진...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[안녕하세요 2박3일로 인제캠핑타운에 다녀왔어요, 강원도에 진입하니 날씨가 참 좋네...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[January 24th 이때부터는 이제 집에있는것이 심심하지도 않고 너무나도 익숙...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[때는 작년 크리스마스이지만 올해부터 일상을 소중히 기록하기위해 블로그를 열씨미 해...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[용화봉정상에서 의암댐 매표소까지 1 78km의 거리인데 인제 절반왔는데 시간이 어...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25132</th>\n",
       "      <td>25384</td>\n",
       "      <td>[까꿍 부팅 시간이 존나 짧은 내 노트북 산지 2년 됐나 아직도 새거 그대로다 십년...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25133</th>\n",
       "      <td>25385</td>\n",
       "      <td>[강원도 당일치기 버스투어 오후 일정 인제 자작나무숲 달리고 바로 속초로 넘어갔다,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25134</th>\n",
       "      <td>25386</td>\n",
       "      <td>[맙소사 2022년이 이제 거의 마무리 되어가고 있다, 내 26살이 이렇게 가버리다...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25135</th>\n",
       "      <td>25387</td>\n",
       "      <td>[인제 메종카누네 입실 3시 퇴실 12시 애견동반가능 정원 4인 3견 까지 가능 예...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25136</th>\n",
       "      <td>25388</td>\n",
       "      <td>[제부여객 2번 구간 1 2번 경진여객차고지 기점 조암시장 장안여자중학교 사곡사거리...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25137 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       post_index                                               text\n",
       "0               0  [이렇게 따끈따끈한 근황 업로드는 처음이다, 기억이 증발하기 전에 기록 코로나 확진...\n",
       "1               1  [안녕하세요 2박3일로 인제캠핑타운에 다녀왔어요, 강원도에 진입하니 날씨가 참 좋네...\n",
       "2               2  [January 24th 이때부터는 이제 집에있는것이 심심하지도 않고 너무나도 익숙...\n",
       "3               3  [때는 작년 크리스마스이지만 올해부터 일상을 소중히 기록하기위해 블로그를 열씨미 해...\n",
       "4               4  [용화봉정상에서 의암댐 매표소까지 1 78km의 거리인데 인제 절반왔는데 시간이 어...\n",
       "...           ...                                                ...\n",
       "25132       25384  [까꿍 부팅 시간이 존나 짧은 내 노트북 산지 2년 됐나 아직도 새거 그대로다 십년...\n",
       "25133       25385  [강원도 당일치기 버스투어 오후 일정 인제 자작나무숲 달리고 바로 속초로 넘어갔다,...\n",
       "25134       25386  [맙소사 2022년이 이제 거의 마무리 되어가고 있다, 내 26살이 이렇게 가버리다...\n",
       "25135       25387  [인제 메종카누네 입실 3시 퇴실 12시 애견동반가능 정원 4인 3견 까지 가능 예...\n",
       "25136       25388  [제부여객 2번 구간 1 2번 경진여객차고지 기점 조암시장 장안여자중학교 사곡사거리...\n",
       "\n",
       "[25137 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.groupby('post_index')['text'].apply(list).reset_index()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (716187663.py, line 60)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 60\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mdksl rmfja dlrp eheocp anjrk whgdmsrjdkl.//.? rmslRk aksgwl dksgdmaus\u001b[39m\n         ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import logging\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from pandarallel import pandarallel\n",
    "from tqdm import tqdm\n",
    "\n",
    "# tqdm + pandas 연동\n",
    "tqdm.pandas()\n",
    "\n",
    "# 불용어 리스트 정의 (예시)\n",
    "\n",
    "\n",
    "# 텍스트 하나로 합치기\n",
    "def get_remove_stop_words_fn(stopwords):\n",
    "    def remove_stop_words(text):\n",
    "        words = text.split()\n",
    "        return ' '.join([word for word in words if word not in stopwords])\n",
    "    return remove_stop_words\n",
    "\n",
    "\n",
    "\n",
    "#형태소 분석 + 명사만 + 불용어 제거\n",
    "def get_tokens_sep_fn(stopwords):\n",
    "    def tokens_sep(text):\n",
    "        from konlpy.tag import Okt\n",
    "        okt = Okt()\n",
    "        morphs = okt.pos(text, stem=True)\n",
    "        return [word for word, pos in morphs if pos == 'Noun' and word not in stopwords]\n",
    "    return tokens_sep\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 한글자 지우기\n",
    "def remove_one_char_words(text):\n",
    "    import re\n",
    "    text = re.sub(r'\\b[가-힣]\\b', '', text)\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "\n",
    "# 로깅 설정\n",
    "def setup_logging(output_dir):\n",
    "    #os.path.join : os에 맞춰서 자동로 경로 처리\n",
    "    log_path = os.path.join(output_dir, \"process.log\")\n",
    "    #logging.basicConfig : 모듈의 기본 설정함수 로그 메세지를 어떻게 찍을지, 어디로 보낼지, 어떤 형식으로 할지 등을 한번에 설정\n",
    "    logging.basicConfig(\n",
    "        #level은 로그의 심각도를 나타냄. 여기서는 INFO로 로그의 정보만을 제공\n",
    "        level=logging.INFO,\n",
    "        #저장되는 로그의 메세지 포맷형식. logging에서 지정된 포맷형식을 작성해야함\n",
    "        #asctime : 로그날짜시간, levlename : 로그level이름, message : 내가 작성할 메세지\n",
    "        format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "        #handlers : 로그를 어디로 출력할지 지정해주는 파라미터\n",
    "        handlers=[]\n",
    "            # FileHandler() : 로그를 파일로 저장하는 파라미터\n",
    "            logging.FileHandler(log_path, encoding=\"utf-8\"),\n",
    "            #StreamHandler : 로그를 화면(콘솔)에 보여주는 파라미터. 실행중에 로그가 실시간으로 보여짐\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "    #logging.info : INFO레벨의 로그 메세지를 찍는 함수\n",
    "    logging.info(f\"로그 파일 저장 위치: {log_path}\")\n",
    "\n",
    "\n",
    "# 복합명사 정의\n",
    "#명사+명사 조합을 함수가 참고해서 만들 수 있도록 복합명사가 들어있는 패턴을 미리 정의\n",
    "#지금 n-gram에서는 명사만 뽑아서 보기때문에 패턴도 명사+명사로 만들었지만 경우에따라\n",
    "#명사+동사, 명사+형용사로도 만들수있음\n",
    "COMPOUNDS = [\"브레이크 타임\"]\n",
    "PATTERNS = [(phrase.split(), \"\".join(phrase.split())) for phrase in COMPOUNDS]\n",
    "\n",
    "\n",
    "\n",
    "# COMPOUNDS = [\"브레이크 타임\", \"물고기 어항\"]\n",
    "\n",
    "# PATTERNS = [(phrase.split(), \"\".join(phrase.split())) for phrase in COMPOUNDS]\n",
    "# [('물고기','어항'), '물고기어항'] 이렇게 패턴 출력\n",
    "\n",
    "# 복합명사 처리 함수\n",
    "def merge_compound(tokens):\n",
    "    i, merged = 0, []\n",
    "    while i < len(tokens):\n",
    "        for parts, joined in PATTERNS:\n",
    "            n = len(parts)\n",
    "            if tokens[i:i+n] == parts:\n",
    "                merged.append(joined)\n",
    "                i += n\n",
    "                break\n",
    "        else:\n",
    "            merged.append(tokens[i])\n",
    "            i += 1\n",
    "    return merged\n",
    "\n",
    "def remove_noise(tokens, stopwords):\n",
    "    return [t for t in tokens if len(t) > 1 and t not in stopwords]\n",
    "\n",
    "def make_bigrams(tokens):\n",
    "    return list(zip(tokens, tokens[1:]))\n",
    "\n",
    "def compute_pmi(w1, w2, cnt, unigram_counts, total_tokens, total_bigrams):\n",
    "    p_w1 = unigram_counts[w1] / total_tokens\n",
    "    p_w2 = unigram_counts[w2] / total_tokens\n",
    "    p_w1w2 = cnt / total_bigrams\n",
    "    return math.log2(p_w1w2 / (p_w1 * p_w2)) if p_w1w2 > 0 else 0.0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 메인 프로세스\n",
    "def main(input_path, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    setup_logging(output_dir)\n",
    "\n",
    "    try:\n",
    "        logging.info(\"데이터 파일 읽는 중\")\n",
    "        df = pd.read_csv(input_path, encoding='utf-8', sep='\\t')\n",
    "        df = df[['text']].copy()\n",
    "        logging.info(f\"데이터 로딩 완료. shape: {df.shape}\")\n",
    "\n",
    "        stopwords = set(stopwords_ko)\n",
    "        pandarallel.initialize(progress_bar=True)\n",
    "\n",
    "        remove_stop_words_fn = get_remove_stop_words_fn(stopwords)\n",
    "        tokens_sep_fn = get_tokens_sep_fn(stopwords)\n",
    "\n",
    "        logging.info(\"한 글자 단어 제거 중...\")\n",
    "        df['remove_one_char_words'] = df['text'].parallel_apply(remove_one_char_words)\n",
    "\n",
    "        logging.info(\"불용어 제거 중...\")\n",
    "        df['remove_stopword'] = df['remove_one_char_words'].parallel_apply(remove_stop_words_fn)\n",
    "\n",
    "        logging.info(\"형태소 분석 중...\")\n",
    "        df['noun_tokens'] = df['remove_stopword'].parallel_apply(tokens_sep_fn)\n",
    "\n",
    "        logging.info(\"복합명사 합치기 중...\")\n",
    "        df['noun_tokens_merged'] = df['noun_tokens'].apply(merge_compound)\n",
    "\n",
    "        logging.info(\"다시 불용어 제거 중...\")\n",
    "        df['noun_tokens_merged_clean'] = df['noun_tokens_merged'].apply(lambda x: remove_noise(x, stopwords))\n",
    "\n",
    "        logging.info(\"바이그램 생성 중...\")\n",
    "        df['bigrams'] = df['noun_tokens_merged_clean'].apply(make_bigrams)\n",
    "\n",
    "        logging.info(\"바이그램 빈도 집계 중...\")\n",
    "        all_bigrams = [bg for bg_list in df[\"bigrams\"] for bg in bg_list]\n",
    "        bigram_counts = Counter(all_bigrams)\n",
    "        top200 = bigram_counts.most_common(200)\n",
    "\n",
    "        result_df = pd.DataFrame(top200, columns=[\"bigram\", \"count\"])\n",
    "        result_df[[\"word1\", \"word2\"]] = pd.DataFrame(result_df[\"bigram\"].tolist(), index=result_df.index)\n",
    "        result_df = result_df[[\"word1\", \"word2\", \"count\"]]\n",
    "\n",
    "        logging.info(\"유니그램 빈도 집계 중...\")\n",
    "        all_tokens = [token for tokens in df['noun_tokens_merged_clean'] for token in tokens]\n",
    "        unigram_counts = Counter(all_tokens)\n",
    "        total_tokens = sum(unigram_counts.values())\n",
    "        total_bigrams = sum(bigram_counts.values())\n",
    "\n",
    "        logging.info(\"PMI 계산 중...\")\n",
    "        result_df['PMI'] = result_df.apply(\n",
    "            lambda row: compute_pmi(row['word1'], row['word2'], row['count'],\n",
    "                                    unigram_counts, total_tokens, total_bigrams),\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        result_df.to_csv(os.path.join(output_dir, \"bigram_top200.csv\"), encoding='utf-8', index=False)\n",
    "        df[['bigrams']].to_csv(os.path.join(output_dir, \"bigram_rawpair.csv\"), encoding='utf-8', index=False)\n",
    "\n",
    "        logging.info(f\"작업 끄읏 ~~~ 결과가 {output_dir}에 저장되었습니다.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"에러 발생: {e}\", exc_info=True)\n",
    "\n",
    "\n",
    "# 실행\n",
    "if __name__ == \"__main__\":\n",
    "    input_path = r\"C:\\Users\\user\\Desktop\\아나콘다_data_code\\workspace\\인제2022문장분리.csv\"\n",
    "    output_dir = r\"C:\\Users\\user\\Desktop\\아나콘다_data_code\\workspace\"\n",
    "    main(input_path, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>post_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>전국 여러 도시에서 이색 빙어축제 얼음축제 겨울축제가 열리는 요즘 강원도 인제에서 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023년 1월 20일 이미 축제를 시작해 오는 1월 29일까지 인제군 남면 부평리...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1월 20일 개막식을 시작으로 인제 빙어 축제는 군민 올림픽 강원 도지사배 전국 얼...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>장소는 내비게이션에 강원도 인제군 남면 부평리 555 2번지를 입력 면 갈 수 있고...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>빙어낚시는 빙어축제의 가장 메인이벤트로 낚시도구는 전부 무료로 제공해 주지만 낚시에...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499914</th>\n",
       "      <td>쥬빌리와의 만남이 우리 학생들의 미래에 큰 발판이 되길 바랍니다</td>\n",
       "      <td>25368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499915</th>\n",
       "      <td>1차 설명회에 이어 많은 분들의 요청으로 2 번째 설명회를 진행하게 되었습니다</td>\n",
       "      <td>25368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499916</th>\n",
       "      <td>빠르게 자리고 차고 있으니 관심있는 학부모님들께서는 서둘러 예약부탁드립니다</td>\n",
       "      <td>25368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499917</th>\n",
       "      <td>쥬빌리를 향한 아낌없는 사랑과 관심 감사드립니다</td>\n",
       "      <td>25368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499918</th>\n",
       "      <td>상담 설명회 문의는 02 403 051로 데스크에 문의 부탁드립니다</td>\n",
       "      <td>25368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>499919 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  post_index\n",
       "0       전국 여러 도시에서 이색 빙어축제 얼음축제 겨울축제가 열리는 요즘 강원도 인제에서 ...           0\n",
       "1       2023년 1월 20일 이미 축제를 시작해 오는 1월 29일까지 인제군 남면 부평리...           0\n",
       "2       1월 20일 개막식을 시작으로 인제 빙어 축제는 군민 올림픽 강원 도지사배 전국 얼...           0\n",
       "3       장소는 내비게이션에 강원도 인제군 남면 부평리 555 2번지를 입력 면 갈 수 있고...           0\n",
       "4       빙어낚시는 빙어축제의 가장 메인이벤트로 낚시도구는 전부 무료로 제공해 주지만 낚시에...           0\n",
       "...                                                   ...         ...\n",
       "499914                쥬빌리와의 만남이 우리 학생들의 미래에 큰 발판이 되길 바랍니다       25368\n",
       "499915        1차 설명회에 이어 많은 분들의 요청으로 2 번째 설명회를 진행하게 되었습니다       25368\n",
       "499916          빠르게 자리고 차고 있으니 관심있는 학부모님들께서는 서둘러 예약부탁드립니다       25368\n",
       "499917                         쥬빌리를 향한 아낌없는 사랑과 관심 감사드립니다       25368\n",
       "499918              상담 설명회 문의는 02 403 051로 데스크에 문의 부탁드립니다       25368\n",
       "\n",
       "[499919 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('인제2023문장분리.csv',encoding ='utf-8', sep = '\\t')\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[전국 여러 도시에서 이색 빙어축제 얼음축제 겨울축제가 열리는 요즘 강원도 인제에서...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[01 16 월요일 오늘의점심 전에 나왔던 오징어까스 또 나옴 오늘의독서 동화책을 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[44번 국도는 경기도 양평군 청운면과 양양군을 잇는 도로이다, 44번 국도는 무엇...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[K 매느리분들 설날 잘 치루셨지요, 전 결혼하고 첫 명절을 치룬것 마냥 이게 매누...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[내 생일 다음은 설날이네, 새해복많이받으세요, 공교롭게 1월 20일 다음날은 설날...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25167</th>\n",
       "      <td>25364</td>\n",
       "      <td>[용대리산채랑황태랑 강원 인제군 북면 백담로 22 1층 용대리산채랑황태랑 네이버 방...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25168</th>\n",
       "      <td>25365</td>\n",
       "      <td>[새해 목표 여유 갖고 정진하기 존재하지 않는 스티커입니다, 올해 많은 일들이 후루...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25169</th>\n",
       "      <td>25366</td>\n",
       "      <td>[용대리산채랑황태랑 강원 인제군 북면 백담로 22 1층 용대리산채랑황태랑 네이버 방...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25170</th>\n",
       "      <td>25367</td>\n",
       "      <td>[그 말을 하고 나는 그녀에게 전화를 했다, 뭔 일이야, 너가 전화를 다하고 아 결...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25171</th>\n",
       "      <td>25368</td>\n",
       "      <td>[안녕하세요 송파 위례 기초 영유연계 프로그램으로 14년째 많은 사랑을 받고 있는 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25172 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       post_index                                               text\n",
       "0               0  [전국 여러 도시에서 이색 빙어축제 얼음축제 겨울축제가 열리는 요즘 강원도 인제에서...\n",
       "1               1  [01 16 월요일 오늘의점심 전에 나왔던 오징어까스 또 나옴 오늘의독서 동화책을 ...\n",
       "2               2  [44번 국도는 경기도 양평군 청운면과 양양군을 잇는 도로이다, 44번 국도는 무엇...\n",
       "3               3  [K 매느리분들 설날 잘 치루셨지요, 전 결혼하고 첫 명절을 치룬것 마냥 이게 매누...\n",
       "4               4  [내 생일 다음은 설날이네, 새해복많이받으세요, 공교롭게 1월 20일 다음날은 설날...\n",
       "...           ...                                                ...\n",
       "25167       25364  [용대리산채랑황태랑 강원 인제군 북면 백담로 22 1층 용대리산채랑황태랑 네이버 방...\n",
       "25168       25365  [새해 목표 여유 갖고 정진하기 존재하지 않는 스티커입니다, 올해 많은 일들이 후루...\n",
       "25169       25366  [용대리산채랑황태랑 강원 인제군 북면 백담로 22 1층 용대리산채랑황태랑 네이버 방...\n",
       "25170       25367  [그 말을 하고 나는 그녀에게 전화를 했다, 뭔 일이야, 너가 전화를 다하고 아 결...\n",
       "25171       25368  [안녕하세요 송파 위례 기초 영유연계 프로그램으로 14년째 많은 사랑을 받고 있는 ...\n",
       "\n",
       "[25172 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.groupby('post_index')['text'].apply(list).reset_index()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-16 11:08:07,962 [INFO] 로그 파일 저장 위치: C:\\Users\\user\\Desktop\\아나콘다_data_code\\workspace\\process.log\n",
      "2025-05-16 11:08:07,963 [INFO] 데이터 파일 읽는 중\n",
      "2025-05-16 11:08:08,777 [INFO] 데이터 로딩 완료. shape: (499919, 1)\n",
      "2025-05-16 11:08:08,778 [INFO] 한 글자 단어 제거 중...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 6 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "\n",
      "WARNING: You are on Windows. If you detect any issue with pandarallel, be sure you checked out the Troubleshooting page:\n",
      "https://nalepae.github.io/pandarallel/troubleshooting/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33d524347a8d4113bd688643d341bb7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=83320), Label(value='0 / 83320')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-16 11:08:11,400 [INFO] 불용어 제거 중...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ef3e8e1724642a79474bd0ca6988d34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=83320), Label(value='0 / 83320')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-16 11:08:13,665 [INFO] 형태소 분석 중...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03b5f9e04abe474cb1ff6eed7c520f0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=83320), Label(value='0 / 83320')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-16 11:12:23,441 [INFO] 복합명사 합치기 중...\n",
      "2025-05-16 11:12:28,340 [INFO] 다시 불용어 제거 중...\n",
      "2025-05-16 11:12:29,693 [INFO] 바이그램 생성 중...\n",
      "2025-05-16 11:12:31,205 [INFO] 바이그램 빈도 집계 중...\n",
      "2025-05-16 11:12:33,657 [INFO] 유니그램 빈도 집계 중...\n",
      "2025-05-16 11:12:34,403 [INFO] PMI 계산 중...\n",
      "2025-05-16 11:12:37,202 [INFO] 작업 끄읏 ~~~ 결과가 C:\\Users\\user\\Desktop\\아나콘다_data_code\\workspace에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import logging\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from pandarallel import pandarallel\n",
    "from tqdm import tqdm\n",
    "\n",
    "# tqdm + pandas 연동\n",
    "tqdm.pandas()\n",
    "\n",
    "# 불용어 리스트 정의 (예시)\n",
    "\n",
    "\n",
    "# 병렬 함수 생성기\n",
    "def get_remove_stop_words_fn(stopwords):\n",
    "    def remove_stop_words(text):\n",
    "        words = text.split()\n",
    "        return ' '.join([word for word in words if word not in stopwords])\n",
    "    return remove_stop_words\n",
    "\n",
    "def get_tokens_sep_fn(stopwords):\n",
    "    def tokens_sep(text):\n",
    "        from konlpy.tag import Okt\n",
    "        okt = Okt()\n",
    "        morphs = okt.pos(text, stem=True)\n",
    "        return [word for word, pos in morphs if pos == 'Noun' and word not in stopwords]\n",
    "    return tokens_sep\n",
    "\n",
    "# 병렬 함수\n",
    "def remove_one_char_words(text):\n",
    "    import re\n",
    "    text = re.sub(r'\\b[가-힣]\\b', '', text)\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "# 로깅 설정\n",
    "def setup_logging(output_dir):\n",
    "    log_path = os.path.join(output_dir, \"process.log\")\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_path, encoding=\"utf-8\"),\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "    logging.info(f\"로그 파일 저장 위치: {log_path}\")\n",
    "\n",
    "# 복합명사 정의\n",
    "COMPOUNDS = [\"브레이크 타임\"]\n",
    "PATTERNS = [(phrase.split(), \"\".join(phrase.split())) for phrase in COMPOUNDS]\n",
    "\n",
    "# 일반 처리 함수들\n",
    "def merge_compound(tokens):\n",
    "    i, merged = 0, []\n",
    "    while i < len(tokens):\n",
    "        matched = False\n",
    "        for parts, joined in PATTERNS:\n",
    "            n = len(parts)\n",
    "            if tokens[i:i+n] == parts:\n",
    "                merged.append(joined)\n",
    "                i += n\n",
    "                matched = True\n",
    "                break\n",
    "        if not matched:\n",
    "            merged.append(tokens[i])\n",
    "            i += 1\n",
    "    return merged\n",
    "\n",
    "def remove_noise(tokens, stopwords):\n",
    "    return [t for t in tokens if len(t) > 1 and t not in stopwords]\n",
    "\n",
    "def make_bigrams(tokens):\n",
    "    return list(zip(tokens, tokens[1:]))\n",
    "\n",
    "def compute_pmi(w1, w2, cnt, unigram_counts, total_tokens, total_bigrams):\n",
    "    p_w1 = unigram_counts[w1] / total_tokens\n",
    "    p_w2 = unigram_counts[w2] / total_tokens\n",
    "    p_w1w2 = cnt / total_bigrams\n",
    "    return math.log2(p_w1w2 / (p_w1 * p_w2)) if p_w1w2 > 0 else 0.0\n",
    "\n",
    "# 메인 프로세스\n",
    "def main(input_path, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    setup_logging(output_dir)\n",
    "\n",
    "    try:\n",
    "        logging.info(\"데이터 파일 읽는 중\")\n",
    "        df = pd.read_csv(input_path, encoding='utf-8', sep='\\t')\n",
    "        df = df[['text']].copy()\n",
    "        logging.info(f\"데이터 로딩 완료. shape: {df.shape}\")\n",
    "\n",
    "        stopwords = set(stopwords_ko)\n",
    "        pandarallel.initialize(progress_bar=True)\n",
    "\n",
    "        remove_stop_words_fn = get_remove_stop_words_fn(stopwords)\n",
    "        tokens_sep_fn = get_tokens_sep_fn(stopwords)\n",
    "\n",
    "        logging.info(\"한 글자 단어 제거 중...\")\n",
    "        df['remove_one_char_words'] = df['text'].parallel_apply(remove_one_char_words)\n",
    "\n",
    "        logging.info(\"불용어 제거 중...\")\n",
    "        df['remove_stopword'] = df['remove_one_char_words'].parallel_apply(remove_stop_words_fn)\n",
    "\n",
    "        logging.info(\"형태소 분석 중...\")\n",
    "        df['noun_tokens'] = df['remove_stopword'].parallel_apply(tokens_sep_fn)\n",
    "\n",
    "        logging.info(\"복합명사 합치기 중...\")\n",
    "        df['noun_tokens_merged'] = df['noun_tokens'].apply(merge_compound)\n",
    "\n",
    "        logging.info(\"다시 불용어 제거 중...\")\n",
    "        df['noun_tokens_merged_clean'] = df['noun_tokens_merged'].apply(lambda x: remove_noise(x, stopwords))\n",
    "\n",
    "        logging.info(\"바이그램 생성 중...\")\n",
    "        df['bigrams'] = df['noun_tokens_merged_clean'].apply(make_bigrams)\n",
    "\n",
    "        logging.info(\"바이그램 빈도 집계 중...\")\n",
    "        all_bigrams = [bg for bg_list in df[\"bigrams\"] for bg in bg_list]\n",
    "        bigram_counts = Counter(all_bigrams)\n",
    "        top200 = bigram_counts.most_common(200)\n",
    "\n",
    "        result_df = pd.DataFrame(top200, columns=[\"bigram\", \"count\"])\n",
    "        result_df[[\"word1\", \"word2\"]] = pd.DataFrame(result_df[\"bigram\"].tolist(), index=result_df.index)\n",
    "        result_df = result_df[[\"word1\", \"word2\", \"count\"]]\n",
    "\n",
    "        logging.info(\"유니그램 빈도 집계 중...\")\n",
    "        all_tokens = [token for tokens in df['noun_tokens_merged_clean'] for token in tokens]\n",
    "        unigram_counts = Counter(all_tokens)\n",
    "        total_tokens = sum(unigram_counts.values())\n",
    "        total_bigrams = sum(bigram_counts.values())\n",
    "\n",
    "        logging.info(\"PMI 계산 중...\")\n",
    "        result_df['PMI'] = result_df.apply(\n",
    "            lambda row: compute_pmi(row['word1'], row['word2'], row['count'],\n",
    "                                    unigram_counts, total_tokens, total_bigrams),\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        result_df.to_csv(os.path.join(output_dir, \"bigram_top200.csv\"), encoding='utf-8', index=False)\n",
    "        df[['bigrams']].to_csv(os.path.join(output_dir, \"bigram_rawpair.csv\"), encoding='utf-8', index=False)\n",
    "\n",
    "        logging.info(f\"작업 끄읏 ~~~ 결과가 {output_dir}에 저장되었습니다.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"에러 발생: {e}\", exc_info=True)\n",
    "\n",
    "# 실행\n",
    "if __name__ == \"__main__\":\n",
    "    input_path = r\"C:\\Users\\user\\Desktop\\아나콘다_data_code\\workspace\\인제2023문장분리.csv\"\n",
    "    output_dir = r\"C:\\Users\\user\\Desktop\\아나콘다_data_code\\workspace\"\n",
    "    main(input_path, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 11:28:49,346 [INFO] 로그 파일 저장 위치: C:\\Users\\user\\Desktop\\아나콘다_data_code\\workspace\\process.log\n",
      "2025-05-07 11:28:49,347 [INFO] 데이터 파일 읽는 중\n",
      "2025-05-07 11:28:49,936 [INFO] 데이터 로딩 완료. shape: (358409, 1)\n",
      "2025-05-07 11:28:49,938 [INFO] 한 글자 단어 제거 중...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 6 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "\n",
      "WARNING: You are on Windows. If you detect any issue with pandarallel, be sure you checked out the Troubleshooting page:\n",
      "https://nalepae.github.io/pandarallel/troubleshooting/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f3e7f895e234e388231f1159643ab9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=59735), Label(value='0 / 59735')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 11:28:52,313 [INFO] 불용어 제거 중...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6d06a4a1f084b1b8e554ea400a0ed45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=59735), Label(value='0 / 59735')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 11:28:54,462 [INFO] 형태소 분석 중...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cb8c271c6eb4e9e9b9b098d20ce9ab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=59735), Label(value='0 / 59735')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 11:30:58,368 [INFO] 복합명사 합치기 중...\n",
      "2025-05-07 11:30:59,468 [INFO] 다시 불용어 제거 중...\n",
      "2025-05-07 11:30:59,963 [INFO] 바이그램 생성 중...\n",
      "2025-05-07 11:31:00,492 [INFO] 바이그램 빈도 집계 중...\n",
      "2025-05-07 11:31:01,287 [INFO] 유니그램 빈도 집계 중...\n",
      "2025-05-07 11:31:01,565 [INFO] PMI 계산 중...\n",
      "2025-05-07 11:31:03,006 [INFO] 작업 끄읏 ~~~ 결과가 C:\\Users\\user\\Desktop\\아나콘다_data_code\\workspace에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import logging\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from pandarallel import pandarallel\n",
    "from tqdm import tqdm\n",
    "\n",
    "# tqdm + pandas 연동\n",
    "tqdm.pandas()\n",
    "\n",
    "# 불용어 리스트 정의 (예시)\n",
    "\n",
    "\n",
    "# 병렬 함수 생성기\n",
    "def get_remove_stop_words_fn(stopwords):\n",
    "    def remove_stop_words(text):\n",
    "        words = text.split()\n",
    "        return ' '.join([word for word in words if word not in stopwords])\n",
    "    return remove_stop_words\n",
    "\n",
    "def get_tokens_sep_fn(stopwords):\n",
    "    def tokens_sep(text):\n",
    "        from konlpy.tag import Okt\n",
    "        okt = Okt()\n",
    "        morphs = okt.pos(text, stem=True)\n",
    "        return [word for word, pos in morphs if pos == 'Noun' and word not in stopwords]\n",
    "    return tokens_sep\n",
    "\n",
    "# 병렬 함수\n",
    "def remove_one_char_words(text):\n",
    "    import re\n",
    "    text = re.sub(r'\\b[가-힣]\\b', '', text)\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "# 로깅 설정\n",
    "def setup_logging(output_dir):\n",
    "    log_path = os.path.join(output_dir, \"process.log\")\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_path, encoding=\"utf-8\"),\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "    logging.info(f\"로그 파일 저장 위치: {log_path}\")\n",
    "\n",
    "# 복합명사 정의\n",
    "COMPOUNDS = [\"브레이크 타임\"]\n",
    "PATTERNS = [(phrase.split(), \"\".join(phrase.split())) for phrase in COMPOUNDS]\n",
    "\n",
    "# 일반 처리 함수들\n",
    "def merge_compound(tokens):\n",
    "    i, merged = 0, []\n",
    "    while i < len(tokens):\n",
    "        matched = False\n",
    "        for parts, joined in PATTERNS:\n",
    "            n = len(parts)\n",
    "            if tokens[i:i+n] == parts:\n",
    "                merged.append(joined)\n",
    "                i += n\n",
    "                matched = True\n",
    "                break\n",
    "        if not matched:\n",
    "            merged.append(tokens[i])\n",
    "            i += 1\n",
    "    return merged\n",
    "\n",
    "def remove_noise(tokens, stopwords):\n",
    "    return [t for t in tokens if len(t) > 1 and t not in stopwords]\n",
    "\n",
    "def make_bigrams(tokens):\n",
    "    return list(zip(tokens, tokens[1:]))\n",
    "\n",
    "def compute_pmi(w1, w2, cnt, unigram_counts, total_tokens, total_bigrams):\n",
    "    p_w1 = unigram_counts[w1] / total_tokens\n",
    "    p_w2 = unigram_counts[w2] / total_tokens\n",
    "    p_w1w2 = cnt / total_bigrams\n",
    "    return math.log2(p_w1w2 / (p_w1 * p_w2)) if p_w1w2 > 0 else 0.0\n",
    "\n",
    "# 메인 프로세스\n",
    "def main(input_path, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    setup_logging(output_dir)\n",
    "\n",
    "    try:\n",
    "        logging.info(\"데이터 파일 읽는 중\")\n",
    "        df = pd.read_csv(input_path, encoding='utf-8', sep='\\t')\n",
    "        df = df[['text']].copy()\n",
    "        logging.info(f\"데이터 로딩 완료. shape: {df.shape}\")\n",
    "\n",
    "        stopwords = set(stopwords_ko)\n",
    "        pandarallel.initialize(progress_bar=True)\n",
    "\n",
    "        remove_stop_words_fn = get_remove_stop_words_fn(stopwords)\n",
    "        tokens_sep_fn = get_tokens_sep_fn(stopwords)\n",
    "\n",
    "        logging.info(\"한 글자 단어 제거 중...\")\n",
    "        df['remove_one_char_words'] = df['text'].parallel_apply(remove_one_char_words)\n",
    "\n",
    "        logging.info(\"불용어 제거 중...\")\n",
    "        df['remove_stopword'] = df['remove_one_char_words'].parallel_apply(remove_stop_words_fn)\n",
    "\n",
    "        logging.info(\"형태소 분석 중...\")\n",
    "        df['noun_tokens'] = df['remove_stopword'].parallel_apply(tokens_sep_fn)\n",
    "\n",
    "        logging.info(\"복합명사 합치기 중...\")\n",
    "        df['noun_tokens_merged'] = df['noun_tokens'].apply(merge_compound)\n",
    "\n",
    "        logging.info(\"다시 불용어 제거 중...\")\n",
    "        df['noun_tokens_merged_clean'] = df['noun_tokens_merged'].apply(lambda x: remove_noise(x, stopwords))\n",
    "\n",
    "        logging.info(\"바이그램 생성 중...\")\n",
    "        df['bigrams'] = df['noun_tokens_merged_clean'].apply(make_bigrams)\n",
    "\n",
    "        logging.info(\"바이그램 빈도 집계 중...\")\n",
    "        all_bigrams = [bg for bg_list in df[\"bigrams\"] for bg in bg_list]\n",
    "        bigram_counts = Counter(all_bigrams)\n",
    "        top200 = bigram_counts.most_common(200)\n",
    "\n",
    "        result_df = pd.DataFrame(top200, columns=[\"bigram\", \"count\"])\n",
    "        result_df[[\"word1\", \"word2\"]] = pd.DataFrame(result_df[\"bigram\"].tolist(), index=result_df.index)\n",
    "        result_df = result_df[[\"word1\", \"word2\", \"count\"]]\n",
    "\n",
    "        logging.info(\"유니그램 빈도 집계 중...\")\n",
    "        all_tokens = [token for tokens in df['noun_tokens_merged_clean'] for token in tokens]\n",
    "        unigram_counts = Counter(all_tokens)\n",
    "        total_tokens = sum(unigram_counts.values())\n",
    "        total_bigrams = sum(bigram_counts.values())\n",
    "\n",
    "        logging.info(\"PMI 계산 중...\")\n",
    "        result_df['PMI'] = result_df.apply(\n",
    "            lambda row: compute_pmi(row['word1'], row['word2'], row['count'],\n",
    "                                    unigram_counts, total_tokens, total_bigrams),\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        result_df.to_csv(os.path.join(output_dir, \"bigram_top200.csv\"), encoding='utf-8', index=False)\n",
    "        df[['bigrams']].to_csv(os.path.join(output_dir, \"bigram_rawpair.csv\"), encoding='utf-8', index=False)\n",
    "\n",
    "        logging.info(f\"작업 끄읏 ~~~ 결과가 {output_dir}에 저장되었습니다.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"에러 발생: {e}\", exc_info=True)\n",
    "\n",
    "# 실행\n",
    "if __name__ == \"__main__\":\n",
    "    input_path = r\"C:\\Users\\user\\Desktop\\아나콘다_data_code\\workspace\\인제2024문장분리.csv\"\n",
    "    output_dir = r\"C:\\Users\\user\\Desktop\\아나콘다_data_code\\workspace\"\n",
    "    main(input_path, output_dir)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
